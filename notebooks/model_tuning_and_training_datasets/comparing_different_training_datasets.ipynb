{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "#import matplotlib.pyplot as plt\n",
    "#from matplotlib.ticker import NullFormatter\n",
    "import numpy as np\n",
    "import pickle\n",
    "#from sklearn.manifold import TSNE\n",
    "#from imblearn.over_sampling import SMOTE\n",
    "#from time import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble.forest import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import logging\n",
    "import logging.config\n",
    "logger = logging.getLogger()\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "fh = logging.FileHandler('randomsearch.log') ##### change the log file name!\n",
    "fh.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s', datefmt='%Y-%m-%d %H:%M:%S')\n",
    "fh.setFormatter(formatter)\n",
    "logger.addHandler(fh)\n",
    "\n",
    "from sklearn.metrics import *\n",
    "from sklearn.metrics import roc_curve, auc, classification_report\n",
    "from sklearn.metrics import precision_score as user_acc\n",
    "from sklearn.metrics import recall_score as prod_acc\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, log_loss\n",
    "#from scipy import interp\n",
    "\n",
    "from madmex.validation import validate, pprint_val_dict\n",
    "\n",
    "import warnings\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_file = '/shared_volume/datacube/training_objects/training_mex_landsat_2017_002_L7L8_1415.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ds_file, 'rb') as f:\n",
    "    training_dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4327748,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataset[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data per class. Classes number correspond to id field in madmex_tag table, not to numeric_code filed!!\n",
    "pxpcl = np.array([training_dataset[1][training_dataset[1] == cl].size for cl in range(1,32)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3075, 391632, 360178,  41292,  66594,  44811, 141600,  22293,\n",
       "        76187,   2410, 390418, 119866, 561611,  22691,  86128,  43360,\n",
       "       136050,  12731,   8686, 213173,   1576,  20744,   1906,  41933,\n",
       "        15784,  40880, 523000, 763402,  56011,  43334,  74392])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pxpcl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modification of remove_outliers method to also give as output the outliers, in case we want to explore them\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from madmex.util.numpy import groupby\n",
    "\n",
    "def remove_outliers(X, y, n_estimators=101, max_samples='auto', contamination=0.25,\n",
    "                        bootstrap=True, n_jobs=-1, **kwargs):\n",
    "        \"\"\"Performs outliers detection and removal using Isolation Forest anomaly score\n",
    "        Args:\n",
    "            X (np.ndarray): Array of independent variables of shape (n,m)\n",
    "            y (np.ndarray): Array of dependent variable of shape (n,)\n",
    "            contamination (float): The amount of contamination of the data set,\n",
    "                i.e. the proportion of outliers in the data set. Used when\n",
    "                fitting to define the threshold on the decision function.\n",
    "            max_sample (float): Proportion of observations to draw from X to fit\n",
    "                each estimator\n",
    "            **kwargs: Arguments passed to ``sklearn.ensemble.IsolationForest``\n",
    "        Example:\n",
    "            >>> from sklearn.datasets import make_classification\n",
    "            >>> from madmex.modeling import BaseModel\n",
    "            >>> X, y = make_classification(n_samples=10000, n_features=10,\n",
    "            >>>                            n_classes=5, n_informative=6)\n",
    "            >>> X_clean, y_clean = BaseModel.remove_outliers(X, y)\n",
    "            >>> print('Input shape:', X.shape, 'Output shape:', X_clean.shape)\n",
    "        Return:\n",
    "            tuple: Tuple of filtered X and y arrays (X, y)\n",
    "        \"\"\"\n",
    "        # Split X\n",
    "        grouped = groupby(X, y)\n",
    "        X_list = []\n",
    "        y_list = []\n",
    "        Xo_list = []\n",
    "        yo_list = []\n",
    "        for g in grouped:\n",
    "            isolation_forest = IsolationForest(n_estimators=n_estimators,\n",
    "                                               max_samples=max_samples,\n",
    "                                               contamination=contamination,\n",
    "                                               bootstrap=bootstrap,\n",
    "                                               n_jobs=n_jobs,\n",
    "                                               **kwargs)\n",
    "            isolation_forest.fit(g[1])\n",
    "            is_inlier = isolation_forest.predict(g[1])\n",
    "            is_outlier = np.where(is_inlier == 1, False, True)\n",
    "            is_inlier = np.where(is_inlier == 1, True, False)\n",
    "            X_out = g[1][is_inlier,:]\n",
    "            X_list.append(X_out)\n",
    "            Xo_out = g[1][is_outlier,:]\n",
    "            Xo_list.append(Xo_out)\n",
    "\n",
    "            y_out = np.empty_like(X_out[:,0], dtype=np.int16)\n",
    "            y_out[:] = g[0]\n",
    "            y_list.append(y_out)\n",
    "            yo_out = np.empty_like(Xo_out[:,0], dtype=np.int16)\n",
    "            yo_out[:] = g[0]\n",
    "            yo_list.append(yo_out)\n",
    "        # Concatenate returned arrays\n",
    "        X = np.concatenate(X_list)\n",
    "        y = np.concatenate(y_list)\n",
    "        Xo = np.concatenate(Xo_list)\n",
    "        yo = np.concatenate(yo_list)\n",
    "        return (X, y, Xo, yo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, y is the data without outliers and Xo, yo are the outliers\n",
    "X, y, Xo, yo = remove_outliers(training_dataset[0],training_dataset[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pxpcl_ro = np.array([y[y == cl].size for cl in range(1,32)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pxpcl_o = np.array([yo[yo == cl].size for cl in range(1,32)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3075, 391632, 360178,  41292,  66594,  44811, 141600,  22293,\n",
       "        76187,   2410, 390418, 119866, 561611,  22691,  86128,  43360,\n",
       "       136050,  12731,   8686, 213173,   1576,  20744,   1906,  41933,\n",
       "        15784,  40880, 523000, 763402,  56011,  43334,  74392])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pxpcl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2306, 293724, 270133,  30969,  49945,  33608, 106200,  16720,\n",
       "        57140,   1807, 292813,  89899, 421208,  17018,  64596,  32520,\n",
       "       102037,   9548,   6514, 159880,   1182,  15558,   1429,  31450,\n",
       "        11838,  30660, 392250, 572551,  42008,  32500,  55794])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pxpcl_ro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   769,  97908,  90045,  10323,  16649,  11203,  35400,   5573,\n",
       "        19047,    603,  97605,  29967, 140403,   5673,  21532,  10840,\n",
       "        34013,   3183,   2172,  53293,    394,   5186,    477,  10483,\n",
       "         3946,  10220, 130750, 190851,  14003,  10834,  18598])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pxpcl_o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### split dataset\n",
    "to have a subsample of X, y we take 20000 per class and in case a class has less than 20000, the whole data of that class is taken. We shuffle the data, because X,y is ordered and that is not convenient for training sake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = [np.where(y== cl)[0] for cl in range(1,32)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2306"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indexes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffled(l):\n",
    "    o = []\n",
    "    _ = [o.append(i) for i in l]\n",
    "    random.shuffle(o)\n",
    "    return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(35473234)\n",
    "new_indexes = [ shuffled(indexes[cl])[:20000] if len(indexes[cl]) >= 20000 else shuffled(indexes[cl]) for cl in range(31) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15558"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_indexes[21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_new_indexes = np.array(np.concatenate([new_indexes[0],new_indexes[1],new_indexes[2],new_indexes[3],new_indexes[4],\n",
    "                                              new_indexes[5],new_indexes[6],new_indexes[7],new_indexes[8],new_indexes[9],\n",
    "                                              new_indexes[10],new_indexes[11],new_indexes[12],new_indexes[13],\n",
    "                                              new_indexes[14],new_indexes[15],new_indexes[16],new_indexes[17],\n",
    "                                              new_indexes[18],new_indexes[19],new_indexes[20],new_indexes[21],\n",
    "                                              new_indexes[22],new_indexes[23],new_indexes[24],new_indexes[25],\n",
    "                                              new_indexes[26],new_indexes[27],new_indexes[28],new_indexes[29],\n",
    "                                              new_indexes[30]]),int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "503920"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged_new_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X = X[merged_new_indexes,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_y = y[merged_new_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(503920, 15)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(503920,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We split the new subset into training and test datasets, where the test dataset is the 20%\n",
    "X_train, X_test, y_train, y_test = train_test_split(new_X, new_y, test_size=0.2, random_state=546842346)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_shuff, y_shuff = shuffle(X_train,y_train,random_state=658432434)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data per class of final training dataset\n",
    "pxpcl_tr = np.array([y_train[y_train == cl].size for cl in range(1,32)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1847, 16082, 15960, 16015, 16092, 15900, 15984, 13385, 15998,\n",
       "        1460, 16002, 16040, 15970, 13560, 15989, 15894, 16007,  7615,\n",
       "        5134, 16080,   954, 12512,  1174, 15989,  9442, 15950, 15992,\n",
       "       16015, 16129, 15951, 16014])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pxpcl_tr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_hyper_params():\n",
    "    \"\"\"\n",
    "        Esta función devuelve un diccionario con\n",
    "        los clasificadores que vamos a utilizar y\n",
    "        una rejilla de hiperparámetros\n",
    "    \"\"\"\n",
    "    seed = 234567943\n",
    "    clfs = {'RF': RandomForestClassifier(n_estimators=10, n_jobs=-1, random_state=seed),\n",
    "        'LGB': LGBMClassifier(n_estimators=10, n_jobs=-1, random_state=seed),\n",
    "        'XGB': XGBClassifier(objective='multi:softmax', n_estimators=10, n_jobs=-1, random_state=seed)\n",
    "            }\n",
    "\n",
    "    grid = { \n",
    "    'RF':{'n_estimators': [500,700,900], 'max_depth': [None,30,45], 'max_features': ['sqrt','log2', None],'min_samples_split': [2,3,5], 'n_jobs': [17], 'class_weight': [None, 'balanced'], 'random_state': [seed]},\n",
    "    'LGB': { 'n_estimators': [500,700,900], 'learning_rate' : [0.001,0.01,0.1,0.5], 'n_jobs': [17], 'max_depth': [-1,15,30], 'reg_alpha': [0.0,0.01,0.1,0.5], 'reg_lambda': [0.0,0.01,0.1,0.5], 'random_state': [seed]},\n",
    "    'XGB': { 'objective': ['multi:softmax'], 'n_estimators': [500,700,900], 'n_jobs': [17], 'max_depth': [5,10,15], \n",
    "             'reg_alpha': [0.0,0.01,0.1,0.5], 'reg_lambda': [1,0.9,0.5], 'learning_rate' : [0.001,0.0005], 'gamma': [0,10,20], 'random_state': [seed]}\n",
    "           }\n",
    "\n",
    "    return clfs, grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def magic_loop(models_to_run, clfs, grid, X_train, y_train, X_test, y_test, cv = 5):\n",
    "        modelos = []\n",
    "        for index, clf in enumerate([clfs[x] for x in models_to_run]):\n",
    "            logger.debug(models_to_run[index])\n",
    "            parameter_values = grid[models_to_run[index]]\n",
    "            try:\n",
    "#                    grid_search = GridSearchCV(clf, parameter_values, cv=cv)\n",
    "                    random_search = RandomizedSearchCV(clf, parameter_values, cv=cv, n_iter=10)\n",
    "                    start = time()\n",
    "#                    modelo = grid_search.fit(X_train, y_train)\n",
    "                    modelo = random_search.fit(X_train, y_train)\n",
    "#                    y_pred = modelo.predict(X_test)\n",
    "#                    y_pred_prob = modelo.predict_proba(X_test)[:,1]\n",
    "\n",
    "                    logger.debug(\"----------------------------------------\")\n",
    "                    logger.debug(\"{}\".format(models_to_run[index]))\n",
    "                    logger.debug(\"----------------------------------------\")\n",
    "                    logger.debug(\"Best parameters set found on development set with GridSearchCV:\")\n",
    "                    logger.debug(\" \")\n",
    "                    logger.debug(modelo.best_params_)\n",
    "                    logger.debug(\" \")\n",
    "                    logger.debug(\"Grid scores on development set:\")\n",
    "                    logger.debug(\" \")\n",
    "                    means = modelo.cv_results_['mean_test_score']\n",
    "                    stds = modelo.cv_results_['std_test_score']\n",
    "                    for mean, std, params in zip(means, stds, modelo.cv_results_['params']):\n",
    "                        logger.debug(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "                    logger.debug(\" \")\n",
    "                    modelos.append(modelo)\n",
    "#                    logger.debug(metrics.classification_report(y_pred, y_test))\n",
    "#                    logger.debug(\"Best model accuracy: {}\".format(metrics.accuracy_score(y_test, y_pred)))\n",
    "#                    logger.debug(\"Best model log loss: {}\".format(metrics.log_loss(y_test, y_pred_prob)))\n",
    "#                    logger.debug(\"grid_search took %.2f seconds\" % (time() - start))\n",
    "\n",
    "            except IndexError as e:\n",
    "                logger.debug('Error:', e)\n",
    "                continue\n",
    "        return modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "clfs, grid = define_hyper_params()\n",
    "#models to train\n",
    "models_to_run=['RF','LGB','XGB']\n",
    "\n",
    "modelos = magic_loop(models_to_run, clfs, grid, X_shuff, y_shuff, X_test, y_test, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(modelos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=3,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=900,\n",
       "                       n_jobs=17, oob_score=False, random_state=234567943,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelos[0].best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "Best parameters: {'random_state': 234567943, 'n_jobs': 17, 'n_estimators': 900, 'min_samples_split': 3, 'max_features': 'sqrt', 'max_depth': None, 'class_weight': None}\n"
     ]
    }
   ],
   "source": [
    "print(\"-------------\")\n",
    "print(\"Best parameters: {}\".format(modelos[0].best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7722654389585648"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelos[2].best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([2780.9299521 , 2539.46438828,  797.07712936, 2515.12980523,\n",
       "        3494.61757379, 1554.08900809, 1549.03772554, 3583.1464467 ,\n",
       "        1473.28001885,  818.72612305]),\n",
       " 'std_fit_time': array([150.18664026,  34.43072209,  21.28272577,  46.98247102,\n",
       "        125.60693383,  32.44984775,  40.50586882, 294.69847297,\n",
       "         15.46881802,   6.22328495]),\n",
       " 'mean_score_time': array([16.00794172, 52.63443503,  8.38592067, 17.16482635, 36.21229987,\n",
       "        16.35490947, 16.595929  , 45.42249007, 29.05839672,  8.48639474]),\n",
       " 'std_score_time': array([0.48056158, 0.4275225 , 0.08191802, 0.51925698, 0.70183604,\n",
       "        0.64252379, 0.59420411, 1.05945265, 1.05812072, 0.21452484]),\n",
       " 'param_reg_lambda': masked_array(data=[0.5, 1, 1, 0.5, 0.5, 1, 0.9, 1, 0.9, 0.5],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_reg_alpha': masked_array(data=[0.5, 0.1, 0.1, 0.01, 0.5, 0.0, 0.1, 0.01, 0.1, 0.0],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_random_state': masked_array(data=[234567943, 234567943, 234567943, 234567943, 234567943,\n",
       "                    234567943, 234567943, 234567943, 234567943, 234567943],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_objective': masked_array(data=['multi:softmax', 'multi:softmax', 'multi:softmax',\n",
       "                    'multi:softmax', 'multi:softmax', 'multi:softmax',\n",
       "                    'multi:softmax', 'multi:softmax', 'multi:softmax',\n",
       "                    'multi:softmax'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_jobs': masked_array(data=[17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[500, 700, 500, 500, 700, 900, 900, 900, 900, 500],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[15, 10, 5, 15, 15, 5, 5, 10, 5, 5],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_learning_rate': masked_array(data=[0.001, 0.0005, 0.0005, 0.0005, 0.001, 0.001, 0.0005,\n",
       "                    0.001, 0.0005, 0.0005],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_gamma': masked_array(data=[20, 0, 10, 20, 10, 20, 20, 20, 0, 20],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'reg_lambda': 0.5,\n",
       "   'reg_alpha': 0.5,\n",
       "   'random_state': 234567943,\n",
       "   'objective': 'multi:softmax',\n",
       "   'n_jobs': 17,\n",
       "   'n_estimators': 500,\n",
       "   'max_depth': 15,\n",
       "   'learning_rate': 0.001,\n",
       "   'gamma': 20},\n",
       "  {'reg_lambda': 1,\n",
       "   'reg_alpha': 0.1,\n",
       "   'random_state': 234567943,\n",
       "   'objective': 'multi:softmax',\n",
       "   'n_jobs': 17,\n",
       "   'n_estimators': 700,\n",
       "   'max_depth': 10,\n",
       "   'learning_rate': 0.0005,\n",
       "   'gamma': 0},\n",
       "  {'reg_lambda': 1,\n",
       "   'reg_alpha': 0.1,\n",
       "   'random_state': 234567943,\n",
       "   'objective': 'multi:softmax',\n",
       "   'n_jobs': 17,\n",
       "   'n_estimators': 500,\n",
       "   'max_depth': 5,\n",
       "   'learning_rate': 0.0005,\n",
       "   'gamma': 10},\n",
       "  {'reg_lambda': 0.5,\n",
       "   'reg_alpha': 0.01,\n",
       "   'random_state': 234567943,\n",
       "   'objective': 'multi:softmax',\n",
       "   'n_jobs': 17,\n",
       "   'n_estimators': 500,\n",
       "   'max_depth': 15,\n",
       "   'learning_rate': 0.0005,\n",
       "   'gamma': 20},\n",
       "  {'reg_lambda': 0.5,\n",
       "   'reg_alpha': 0.5,\n",
       "   'random_state': 234567943,\n",
       "   'objective': 'multi:softmax',\n",
       "   'n_jobs': 17,\n",
       "   'n_estimators': 700,\n",
       "   'max_depth': 15,\n",
       "   'learning_rate': 0.001,\n",
       "   'gamma': 10},\n",
       "  {'reg_lambda': 1,\n",
       "   'reg_alpha': 0.0,\n",
       "   'random_state': 234567943,\n",
       "   'objective': 'multi:softmax',\n",
       "   'n_jobs': 17,\n",
       "   'n_estimators': 900,\n",
       "   'max_depth': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'gamma': 20},\n",
       "  {'reg_lambda': 0.9,\n",
       "   'reg_alpha': 0.1,\n",
       "   'random_state': 234567943,\n",
       "   'objective': 'multi:softmax',\n",
       "   'n_jobs': 17,\n",
       "   'n_estimators': 900,\n",
       "   'max_depth': 5,\n",
       "   'learning_rate': 0.0005,\n",
       "   'gamma': 20},\n",
       "  {'reg_lambda': 1,\n",
       "   'reg_alpha': 0.01,\n",
       "   'random_state': 234567943,\n",
       "   'objective': 'multi:softmax',\n",
       "   'n_jobs': 17,\n",
       "   'n_estimators': 900,\n",
       "   'max_depth': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'gamma': 20},\n",
       "  {'reg_lambda': 0.9,\n",
       "   'reg_alpha': 0.1,\n",
       "   'random_state': 234567943,\n",
       "   'objective': 'multi:softmax',\n",
       "   'n_jobs': 17,\n",
       "   'n_estimators': 900,\n",
       "   'max_depth': 5,\n",
       "   'learning_rate': 0.0005,\n",
       "   'gamma': 0},\n",
       "  {'reg_lambda': 0.5,\n",
       "   'reg_alpha': 0.0,\n",
       "   'random_state': 234567943,\n",
       "   'objective': 'multi:softmax',\n",
       "   'n_jobs': 17,\n",
       "   'n_estimators': 500,\n",
       "   'max_depth': 5,\n",
       "   'learning_rate': 0.0005,\n",
       "   'gamma': 20}],\n",
       " 'split0_test_score': array([0.7674831 , 0.75389099, 0.68074657, 0.76712346, 0.77403113,\n",
       "        0.6968562 , 0.68691015, 0.75513115, 0.6872698 , 0.68110622]),\n",
       " 'split1_test_score': array([0.7658804 , 0.75168043, 0.67822507, 0.76569437, 0.77268894,\n",
       "        0.69537664, 0.68435151, 0.75207729, 0.68448793, 0.67817546]),\n",
       " 'split2_test_score': array([0.76564632, 0.75137053, 0.67721331, 0.76537345, 0.77226949,\n",
       "        0.69306427, 0.68311711, 0.75326818, 0.68283184, 0.67737454]),\n",
       " 'split3_test_score': array([0.76369612, 0.75069767, 0.67637829, 0.76427907, 0.7704186 ,\n",
       "        0.69297364, 0.68274109, 0.7519876 , 0.68272868, 0.67656434]),\n",
       " 'split4_test_score': array([0.7646497 , 0.75135209, 0.67884787, 0.76508385, 0.77191873,\n",
       "        0.69627617, 0.68550908, 0.75200953, 0.68581919, 0.67894711]),\n",
       " 'mean_test_score': array([0.76547121, 0.7517984 , 0.67828227, 0.76551089, 0.77226544,\n",
       "        0.69490941, 0.68452582, 0.7528948 , 0.68462752, 0.67843358]),\n",
       " 'std_test_score': array([0.00127058, 0.00109426, 0.00149427, 0.00093304, 0.00116861,\n",
       "        0.00161419, 0.00153963, 0.00121788, 0.00174651, 0.00155496]),\n",
       " 'rank_test_score': array([ 3,  5, 10,  2,  1,  6,  8,  4,  7,  9], dtype=int32)}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelos[2].cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try new hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'reg_lambda': 0.8, 'reg_alpha': 0.2, 'random_state': 234567943, 'objective': 'multi:softmax', \n",
    "          'n_jobs': 17, 'n_estimators': 900, 'max_depth': 15, 'learning_rate': 0.0005, 'gamma': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeloXGB = XGBClassifier(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeloXGB.fit(X_shuff,y_shuff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.0005, max_delta_step=0, max_depth=15,\n",
       "              min_child_weight=1, missing=None, n_estimators=900, n_jobs=17,\n",
       "              nthread=None, objective='multi:softprob', random_state=234567943,\n",
       "              reg_alpha=0.2, reg_lambda=0.8, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeloXGB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### metrics test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_xgb = modeloXGB.predict(X_test)\n",
    "y_pred_prob_test_xgb = modeloXGB.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Best model accuracy: 0.7777821876488331'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report(y_pred_test_xgb, y_test)\n",
    "\"Best model accuracy: {}\".format(accuracy_score(y_test, y_pred_test_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Best model log loss: 1.9005280435239063'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Best model log loss: {}\".format(log_loss(y_test, y_pred_prob_test_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### metrics trainig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_shuff_xgb = modeloXGB.predict(X_shuff)\n",
    "y_pred_prob_shuff_xgb = modeloXGB.predict_proba(X_shuff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Best model accuracy: 0.8576733410065089'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report(y_pred_shuff_xgb, y_shuff)\n",
    "\"Best model accuracy: {}\".format(accuracy_score(y_shuff, y_pred_shuff_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Best model log loss: 1.7649682254908547'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Best model log loss: {}\".format(log_loss(y_shuff, y_pred_prob_shuff_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### metrics test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31]\n",
    "classes_31 = {index: tmp[index-1] for index in range(1,32)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric code    User's Accuracy      Producer's Accuracy  Class Name                                        \n",
      "1               0.94                 0.93                 Bosque de Coníferas: Oyamel, Ayarín y Cedro       \n",
      "2               0.74                 0.75                 Bosque de Coníferas: de Pino y Táscate            \n",
      "3               0.63                 0.59                 Bosque de Encino y Bosque de Galería              \n",
      "4               0.83                 0.78                 Chaparral                                         \n",
      "5               0.78                 0.83                 Mezquital y Matorral Submontano                   \n",
      "6               0.86                 0.88                 Bosque Mesófilo y Selva Baja Perennifolia         \n",
      "7               0.83                 0.81                 Selva Baja y Mediana Subperennifolia, Bosque de Galería y Palmar Natural\n",
      "8               0.90                 0.86                 Manglar y Petén                                   \n",
      "9               0.84                 0.87                 Selva Mediana y Alta Perennifolia                 \n",
      "10              0.73                 0.62                 Selva Alta Subperennifolia                        \n",
      "11              0.80                 0.77                 Selva Baja Caducifolia Subcaducifolia y Matorral Subtropical\n",
      "12              0.82                 0.87                 Selva Mediana Caducifolia y Subcaducifolia        \n",
      "13              0.67                 0.75                 Mezquital Xerofilo Galeria y Desertico Microfilo  \n",
      "14              0.71                 0.88                 Matorral Crasicaule                               \n",
      "15              0.81                 0.92                 Matorral Espinoso Tamaulipeco                     \n",
      "16              0.66                 0.73                 Matorral Sarco-Crasicaule                         \n",
      "17              0.71                 0.72                 Matorral Sarcocaule                               \n",
      "18              0.81                 0.94                 Matorral Sarco-Crasicaule de Neblina              \n",
      "19              0.76                 0.60                 Matorral Rosetofilo Costero                       \n",
      "20              0.77                 0.78                 Matorral Desertico Rosetofilo                     \n",
      "21              0.55                 0.26                 Popal                                             \n",
      "22              0.78                 0.88                 Tular                                             \n",
      "23              0.63                 0.29                 Vegetacion de Dunas Costeras                      \n",
      "24              0.88                 0.89                 Vegetacion de Desiertos Arenosos                  \n",
      "25              0.73                 0.75                 Vegetacion Halofila Hidrofila                     \n",
      "26              0.76                 0.81                 Vegetacion Halofila Xerofila y Gipsofila          \n",
      "27              0.66                 0.52                 Pastizales                                        \n",
      "28              0.65                 0.52                 Tierras Agricolas                                 \n",
      "29              0.80                 0.67                 Urbano y Construido                               \n",
      "30              0.90                 0.81                 Suelo Desnudo                                     \n",
      "31              0.99                 0.97                 Agua                                              \n",
      "-----\n",
      "Overall Accuracy: 0.78\n",
      "\n",
      "-----\n",
      "Confusion matrix\n",
      "-----\n",
      "      | 1       2       3       4       5       6       7       8       9       10      11      12      13      14      15      16      17      18      19      20      21      22      23      24      25      26      27      28      29      30      31     \n",
      "      | ------- ------- ------- ------- ------- ------- ------- ------- ------- ------- ------- ------- ------- ------- ------- ------- ------- ------- ------- ------- ------- ------- ------- ------- ------- ------- ------- ------- ------- ------- -------\n",
      "1     | 429.00  26.00   0.00    0.00    0.00    4.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   \n",
      "2     | 27.00   2941.00 500.00  10.00   103.00  230.00  0.00    0.00    8.00    0.00    52.00   9.00    0.00    27.00   0.00    0.00    0.00    0.00    0.00    2.00    0.00    0.00    0.00    0.00    0.00    0.00    1.00    8.00    0.00    0.00    0.00   \n",
      "3     | 0.00    691.00  2401.00 71.00   177.00  23.00   0.00    0.00    0.00    0.00    283.00  4.00    1.00    264.00  0.00    0.00    3.00    0.00    0.00    20.00   0.00    1.00    0.00    0.00    0.00    0.00    49.00   51.00   0.00    0.00    1.00   \n",
      "4     | 0.00    42.00   105.00  3112.00 79.00   0.00    0.00    0.00    0.00    0.00    26.00   0.00    19.00   78.00   2.00    110.00  44.00   0.00    111.00  221.00  0.00    0.00    0.00    0.00    0.00    0.00    17.00   12.00   7.00    0.00    0.00   \n",
      "5     | 0.00    21.00   102.00  73.00   3246.00 27.00   2.00    1.00    39.00   0.00    59.00   14.00   0.00    11.00   182.00  12.00   7.00    0.00    0.00    20.00   0.00    6.00    0.00    0.00    8.00    0.00    22.00   39.00   15.00   0.00    2.00   \n",
      "6     | 2.00    143.00  11.00   0.00    13.00   3605.00 0.00    0.00    323.00  0.00    0.00    3.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   \n",
      "7     | 0.00    0.00    0.00    0.00    2.00    0.00    3263.00 58.00   140.00  70.00   0.00    460.00  0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    3.00    9.00    0.00    0.00    0.00    0.00    11.00   0.00    0.00    0.00    0.00   \n",
      "8     | 0.00    0.00    0.00    0.00    0.00    0.00    110.00  2861.00 0.00    0.00    0.00    5.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    6.00    332.00  1.00    0.00    5.00    0.00    3.00    1.00    0.00    0.00    11.00  \n",
      "9     | 0.00    0.00    0.00    0.00    21.00   278.00  145.00  0.00    3474.00 11.00   0.00    35.00   0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    4.00    1.00    0.00    0.00    0.00    0.00    33.00   0.00    0.00    0.00    0.00   \n",
      "10    | 0.00    0.00    0.00    0.00    0.00    0.00    90.00   0.00    43.00   214.00  0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   \n",
      "11    | 0.00    15.00   338.00  34.00   141.00  1.00    0.00    2.00    1.00    0.00    3085.00 124.00  0.00    37.00   27.00   3.00    103.00  0.00    0.00    2.00    0.00    0.00    0.00    0.00    0.00    0.00    22.00   63.00   0.00    0.00    0.00   \n",
      "12    | 0.00    5.00    1.00    0.00    20.00   3.00    313.00  7.00    67.00   0.00    53.00   3463.00 0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    3.00    0.00    0.00    0.00    0.00    19.00   6.00    0.00    0.00    0.00   \n",
      "13    | 0.00    0.00    1.00    12.00   0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    3013.00 34.00   52.00   124.00  86.00   11.00   0.00    224.00  0.00    0.00    1.00    92.00   22.00   122.00  83.00   65.00   76.00   12.00   0.00   \n",
      "14    | 0.00    17.00   77.00   41.00   3.00    0.00    0.00    0.00    0.00    0.00    9.00    0.00    28.00   3031.00 0.00    0.00    0.00    0.00    0.00    102.00  0.00    0.00    0.00    0.00    0.00    0.00    101.00  44.00   5.00    0.00    0.00   \n",
      "15    | 0.00    0.00    0.00    0.00    159.00  0.00    0.00    0.00    0.00    0.00    7.00    0.00    19.00   0.00    3673.00 9.00    18.00   0.00    0.00    5.00    0.00    1.00    0.00    0.00    12.00   0.00    23.00   67.00   18.00   0.00    0.00   \n",
      "16    | 0.00    0.00    0.00    60.00   5.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    88.00   1.00    8.00    2988.00 622.00  117.00  117.00  21.00   0.00    0.00    2.00    1.00    18.00   29.00   2.00    10.00   16.00   1.00    0.00   \n",
      "17    | 0.00    0.00    9.00    24.00   3.00    0.00    0.00    0.00    0.00    0.00    89.00   0.00    62.00   0.00    21.00   654.00  2879.00 126.00  12.00   8.00    0.00    0.00    1.00    0.00    10.00   25.00   6.00    28.00   36.00   0.00    0.00   \n",
      "18    | 0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    6.00    0.00    0.00    39.00   37.00   1815.00 0.00    0.00    0.00    0.00    0.00    0.00    11.00   9.00    0.00    13.00   3.00    0.00    0.00   \n",
      "19    | 0.00    0.00    0.00    127.00  0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    1.00    395.00  16.00   0.00    824.00  2.00    0.00    0.00    2.00    0.00    0.00    13.00   0.00    0.00    0.00    0.00    0.00   \n",
      "20    | 0.00    8.00    27.00   107.00  26.00   0.00    0.00    0.00    0.00    0.00    4.00    0.00    257.00  157.00  22.00   67.00   9.00    0.00    2.00    3054.00 0.00    0.00    0.00    0.00    0.00    0.00    116.00  20.00   44.00   0.00    0.00   \n",
      "21    | 0.00    0.00    0.00    0.00    0.00    0.00    3.00    3.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    59.00   146.00  0.00    0.00    0.00    0.00    14.00   3.00    0.00    0.00    0.00   \n",
      "22    | 0.00    0.00    0.00    0.00    7.00    0.00    9.00    214.00  0.00    0.00    1.00    4.00    0.00    0.00    2.00    0.00    0.00    0.00    0.00    0.00    23.00   2694.00 0.00    0.00    36.00   0.00    28.00   17.00   0.00    0.00    11.00  \n",
      "23    | 0.00    0.00    0.00    0.00    0.00    0.00    0.00    5.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    2.00    3.00    15.00   3.00    0.00    0.00    17.00   73.00   1.00    62.00   31.00   3.00    6.00    10.00   22.00   2.00   \n",
      "24    | 0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    28.00   0.00    0.00    2.00    0.00    0.00    0.00    0.00    0.00    0.00    1.00    3581.00 59.00   294.00  0.00    0.00    1.00    45.00   0.00   \n",
      "25    | 0.00    0.00    0.00    0.00    1.00    0.00    0.00    2.00    0.00    0.00    0.00    0.00    74.00   0.00    23.00   3.00    2.00    26.00   0.00    3.00    0.00    72.00   4.00    48.00   1790.00 150.00  2.00    19.00   56.00   108.00  13.00  \n",
      "26    | 0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    162.00  0.00    0.00    30.00   16.00   29.00   4.00    0.00    0.00    0.00    18.00   216.00  114.00  3262.00 0.00    0.00    50.00   149.00  0.00   \n",
      "27    | 0.00    15.00   120.00  17.00   33.00   1.00    17.00   4.00    29.00   0.00    68.00   74.00   238.00  358.00  246.00  13.00   20.00   9.00    0.00    116.00  12.00   68.00   0.00    0.00    8.00    0.00    2093.00 394.00  55.00   0.00    0.00   \n",
      "28    | 0.00    44.00   103.00  28.00   102.00  0.00    0.00    0.00    0.00    0.00    136.00  21.00   158.00  210.00  207.00  22.00   61.00   64.00   3.00    38.00   0.00    38.00   0.00    0.00    39.00   0.00    431.00  2078.00 199.00  0.00    3.00   \n",
      "29    | 0.00    4.00    8.00    13.00   10.00   0.00    0.00    0.00    0.00    0.00    0.00    0.00    227.00  34.00   72.00   64.00   121.00  30.00   5.00    102.00  0.00    0.00    2.00    14.00   101.00  100.00  88.00   252.00  2592.00 32.00   0.00   \n",
      "30    | 0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    107.00  0.00    5.00    11.00   14.00   8.00    1.00    4.00    0.00    0.00    10.00   133.00  146.00  258.00  2.00    0.00    73.00   3262.00 15.00  \n",
      "31    | 0.00    0.00    0.00    0.00    4.00    0.00    0.00    28.00   0.00    0.00    5.00    0.00    0.00    0.00    0.00    5.00    3.00    0.00    1.00    0.00    0.00    51.00   0.00    0.00    25.00   0.00    0.00    3.00    0.00    11.00   3850.00\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix and producer and user accuracies\n",
    "scheme = 'madmex_31'\n",
    "\n",
    "acc_dict = validate(y_true=[classes_31[x] for x in y_test], y_pred=[classes_31[x] for x in y_pred_test_xgb],\n",
    "                            scheme=scheme)\n",
    "pprint_val_dict(acc_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### metrics trainig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric code    User's Accuracy      Producer's Accuracy  Class Name                                        \n",
      "1               0.97                 0.97                 Bosque de Coníferas: Oyamel, Ayarín y Cedro       \n",
      "2               0.84                 0.87                 Bosque de Coníferas: de Pino y Táscate            \n",
      "3               0.79                 0.74                 Bosque de Encino y Bosque de Galería              \n",
      "4               0.93                 0.88                 Chaparral                                         \n",
      "5               0.87                 0.91                 Mezquital y Matorral Submontano                   \n",
      "6               0.92                 0.93                 Bosque Mesófilo y Selva Baja Perennifolia         \n",
      "7               0.90                 0.89                 Selva Baja y Mediana Subperennifolia, Bosque de Galería y Palmar Natural\n",
      "8               0.94                 0.92                 Manglar y Petén                                   \n",
      "9               0.91                 0.93                 Selva Mediana y Alta Perennifolia                 \n",
      "10              0.91                 0.81                 Selva Alta Subperennifolia                        \n",
      "11              0.89                 0.88                 Selva Baja Caducifolia Subcaducifolia y Matorral Subtropical\n",
      "12              0.90                 0.94                 Selva Mediana Caducifolia y Subcaducifolia        \n",
      "13              0.78                 0.84                 Mezquital Xerofilo Galeria y Desertico Microfilo  \n",
      "14              0.81                 0.95                 Matorral Crasicaule                               \n",
      "15              0.84                 0.96                 Matorral Espinoso Tamaulipeco                     \n",
      "16              0.74                 0.83                 Matorral Sarco-Crasicaule                         \n",
      "17              0.81                 0.80                 Matorral Sarcocaule                               \n",
      "18              0.87                 0.98                 Matorral Sarco-Crasicaule de Neblina              \n",
      "19              0.88                 0.74                 Matorral Rosetofilo Costero                       \n",
      "20              0.88                 0.88                 Matorral Desertico Rosetofilo                     \n",
      "21              0.90                 0.55                 Popal                                             \n",
      "22              0.87                 0.95                 Tular                                             \n",
      "23              0.98                 0.54                 Vegetacion de Dunas Costeras                      \n",
      "24              0.92                 0.93                 Vegetacion de Desiertos Arenosos                  \n",
      "25              0.84                 0.87                 Vegetacion Halofila Hidrofila                     \n",
      "26              0.86                 0.89                 Vegetacion Halofila Xerofila y Gipsofila          \n",
      "27              0.84                 0.69                 Pastizales                                        \n",
      "28              0.85                 0.71                 Tierras Agricolas                                 \n",
      "29              0.91                 0.80                 Urbano y Construido                               \n",
      "30              0.96                 0.88                 Suelo Desnudo                                     \n",
      "31              0.99                 0.98                 Agua                                              \n",
      "-----\n",
      "Overall Accuracy: 0.87\n",
      "\n",
      "-----\n",
      "Confusion matrix\n",
      "-----\n",
      "      | 1       2       3       4       5       6       7       8       9       10      11      12      13      14      15      16      17      18      19      20      21      22      23      24      25      26      27      28      29      30      31     \n",
      "      | ------- ------- ------- ------- ------- ------- ------- ------- ------- ------- ------- ------- ------- ------- ------- ------- ------- ------- ------- ------- ------- ------- ------- ------- ------- ------- ------- ------- ------- ------- -------\n",
      "1     | 1791.00 52.00   0.00    0.00    0.00    4.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   \n",
      "2     | 43.00   13934.00 1118.00 6.00    247.00  535.00  0.00    0.00    10.00   0.00    114.00  10.00   0.00    50.00   0.00    0.00    0.00    0.00    0.00    4.00    0.00    0.00    0.00    0.00    0.00    0.00    3.00    8.00    0.00    0.00    0.00   \n",
      "3     | 0.00    1994.00 11817.00 90.00   476.00  38.00   0.00    0.00    0.00    0.00    740.00  7.00    0.00    590.00  8.00    2.00    9.00    0.00    0.00    42.00   0.00    0.00    0.00    0.00    0.00    0.00    73.00   74.00   0.00    0.00    0.00   \n",
      "4     | 0.00    136.00  166.00  14169.00 186.00  0.00    0.00    0.00    0.00    0.00    45.00   0.00    24.00   199.00  18.00   297.00  105.00  0.00    243.00  379.00  0.00    0.00    0.00    0.00    1.00    1.00    26.00   10.00   10.00   0.00    0.00   \n",
      "5     | 0.00    34.00   210.00  134.00  14639.00 50.00   3.00    2.00    71.00   0.00    91.00   21.00   2.00    17.00   587.00  22.00   31.00   0.00    0.00    35.00   0.00    14.00   0.00    0.00    16.00   0.00    27.00   73.00   8.00    0.00    5.00   \n",
      "6     | 9.00    261.00  16.00   0.00    24.00   14764.00 0.00    0.00    814.00  0.00    0.00    12.00   0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   \n",
      "7     | 0.00    0.00    0.00    0.00    6.00    0.00    14193.00 113.00  376.00  92.00   0.00    1174.00 0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    3.00    6.00    0.00    0.00    0.00    0.00    21.00   0.00    0.00    0.00    0.00   \n",
      "8     | 0.00    0.00    0.00    0.00    0.00    0.00    235.00  12274.00 0.00    0.00    0.00    18.00   0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    10.00   831.00  0.00    0.00    5.00    0.00    2.00    0.00    0.00    0.00    10.00  \n",
      "9     | 0.00    3.00    0.00    0.00    36.00   624.00  353.00  2.00    14884.00 19.00   0.00    39.00   0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    1.00    1.00    0.00    0.00    0.00    0.00    36.00   0.00    0.00    0.00    0.00   \n",
      "10    | 0.00    0.00    0.00    0.00    0.00    0.00    180.00  0.00    91.00   1189.00 0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   \n",
      "11    | 0.00    29.00   777.00  43.00   320.00  0.00    0.00    2.00    1.00    0.00    14071.00 256.00  1.00    57.00   58.00   3.00    255.00  0.00    0.00    1.00    0.00    12.00   0.00    0.00    3.00    0.00    27.00   86.00   0.00    0.00    0.00   \n",
      "12    | 0.00    4.00    1.00    0.00    35.00   5.00    674.00  11.00   101.00  0.00    66.00   15116.00 0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    3.00    0.00    0.00    0.00    0.00    16.00   8.00    0.00    0.00    0.00   \n",
      "13    | 0.00    0.00    2.00    22.00   0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    13411.00 106.00  169.00  440.00  169.00  39.00   0.00    556.00  0.00    0.00    1.00    259.00  47.00   285.00  167.00  116.00  177.00  4.00    0.00   \n",
      "14    | 0.00    27.00   122.00  52.00   1.00    0.00    0.00    0.00    0.00    0.00    16.00   0.00    41.00   12867.00 0.00    0.00    2.00    0.00    0.00    235.00  0.00    0.00    0.00    0.00    1.00    0.00    146.00  47.00   3.00    0.00    0.00   \n",
      "15    | 0.00    0.00    0.00    0.00    424.00  0.00    0.00    0.00    0.00    0.00    5.00    0.00    19.00   1.00    15296.00 15.00   26.00   0.00    0.00    9.00    0.00    4.00    0.00    0.00    26.00   0.00    39.00   97.00   28.00   0.00    0.00   \n",
      "16    | 0.00    0.00    0.00    105.00  2.00    0.00    0.00    0.00    0.00    0.00    1.00    0.00    175.00  0.00    16.00   13170.00 1713.00 287.00  247.00  63.00   0.00    0.00    0.00    0.00    46.00   40.00   0.00    6.00    23.00   0.00    0.00   \n",
      "17    | 0.00    0.00    9.00    54.00   10.00   0.00    0.00    0.00    0.00    0.00    229.00  0.00    153.00  0.00    54.00   2083.00 12853.00 328.00  24.00   11.00   0.00    0.00    0.00    0.00    45.00   52.00   1.00    46.00   53.00   0.00    2.00   \n",
      "18    | 0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    4.00    0.00    0.00    49.00   47.00   7468.00 0.00    0.00    0.00    0.00    1.00    0.00    26.00   3.00    0.00    13.00   4.00    0.00    0.00   \n",
      "19    | 0.00    0.00    0.00    257.00  0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    3.00    1032.00 26.00   2.00    3789.00 1.00    0.00    0.00    0.00    0.00    0.00    24.00   0.00    0.00    0.00    0.00    0.00   \n",
      "20    | 0.00    8.00    25.00   225.00  43.00   0.00    0.00    0.00    0.00    0.00    1.00    0.00    577.00  327.00  73.00   214.00  42.00   0.00    3.00    14218.00 0.00    0.00    0.00    0.00    0.00    0.00    225.00  19.00   80.00   0.00    0.00   \n",
      "21    | 0.00    0.00    0.00    0.00    0.00    0.00    15.00   19.00   0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    520.00  367.00  0.00    0.00    3.00    0.00    28.00   2.00    0.00    0.00    0.00   \n",
      "22    | 0.00    0.00    0.00    0.00    15.00   0.00    19.00   452.00  0.00    0.00    2.00    6.00    0.00    0.00    4.00    0.00    0.00    0.00    0.00    0.00    25.00   11844.00 0.00    0.00    70.00   0.00    36.00   17.00   0.00    0.00    22.00  \n",
      "23    | 0.00    0.00    0.00    0.00    0.00    0.00    0.00    7.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    4.00    6.00    35.00   0.00    0.00    0.00    62.00   638.00  8.00    189.00  117.00  1.00    5.00    14.00   80.00   8.00   \n",
      "24    | 0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    56.00   0.00    0.00    8.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    14941.00 123.00  827.00  0.00    0.00    1.00    33.00   0.00   \n",
      "25    | 0.00    0.00    0.00    0.00    3.00    0.00    0.00    1.00    0.00    0.00    0.00    0.00    159.00  0.00    76.00   10.00   7.00    50.00   0.00    5.00    0.00    160.00  3.00    90.00   8206.00 305.00  7.00    59.00   99.00   189.00  13.00  \n",
      "26    | 0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    468.00  0.00    1.00    64.00   27.00   64.00   4.00    2.00    0.00    0.00    4.00    503.00  281.00  14242.00 0.00    0.00    59.00   231.00  0.00   \n",
      "27    | 0.00    30.00   348.00  39.00   131.00  1.00    40.00   4.00    61.00   0.00    187.00  127.00  662.00  983.00  861.00  28.00   109.00  21.00   0.00    291.00  22.00   188.00  0.00    0.00    23.00   1.00    10969.00 755.00  111.00  0.00    0.00   \n",
      "28    | 0.00    79.00   261.00  60.00   236.00  0.00    0.00    3.00    0.00    0.00    299.00  91.00   425.00  531.00  669.00  61.00   157.00  148.00  2.00    80.00   0.00    67.00   0.00    0.00    107.00  4.00    926.00  11426.00 381.00  0.00    2.00   \n",
      "29    | 0.00    3.00    14.00   19.00   22.00   0.00    0.00    0.00    0.00    0.00    3.00    0.00    671.00  101.00  198.00  173.00  249.00  105.00  13.00   241.00  0.00    1.00    4.00    40.00   251.00  278.00  201.00  512.00  12973.00 56.00   1.00   \n",
      "30    | 0.00    0.00    0.00    1.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    369.00  0.00    21.00   31.00   44.00   37.00   2.00    17.00   0.00    0.00    3.00    386.00  283.00  468.00  17.00   11.00   196.00  14046.00 19.00  \n",
      "31    | 0.00    0.00    0.00    1.00    4.00    0.00    0.00    108.00  0.00    0.00    3.00    0.00    0.00    0.00    5.00    9.00    15.00   0.00    0.00    0.00    0.00    128.00  0.00    0.00    63.00   0.00    0.00    10.00   1.00    17.00   15650.00\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix and producer and user accuracies\n",
    "scheme = 'madmex_31'\n",
    "\n",
    "acc_dict = validate(y_true=[classes_31[x] for x in y_shuff], y_pred=[classes_31[x] for x in y_pred_shuff_xgb],\n",
    "#acc_dict = validate(y_true=y_shuff, y_pred=y_pred_shuff_xgb,\n",
    "                            scheme=scheme)\n",
    "pprint_val_dict(acc_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### metrics with coe dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "coe_ds_file = '/shared_volume/datacube/training_objects/training_mexico_coe_nacional_1M_L7L8_1415.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(coe_ds_file, 'rb') as f:\n",
    "    coe_training_dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "coe_X, coe_y_id, coe_Xo, coe_yo_id = remove_outliers(coe_training_dataset[0],coe_training_dataset[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,20,21,22,23,27,28,29,30,31,15,16,17,18,24,25,26,19]\n",
    "coe_y = [tmp[y-1] for y in coe_y_id]\n",
    "coe_yo = [tmp[y-1] for y in coe_yo_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_coe_xgb = modeloXGB.predict(coe_X)\n",
    "y_pred_prob_coe_xgb = modeloXGB.predict_proba(coe_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Best model accuracy: 0.6866415181271057'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report(y_pred_coe_xgb, coe_y)\n",
    "\"Best model accuracy: {}\".format(accuracy_score(coe_y, y_pred_coe_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Best model log loss: 2.062787560020533'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Best model log loss: {}\".format(log_loss(coe_y, y_pred_prob_coe_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,20,21,22,23,27,28,29,30,31,15,16,17,18,24,25,26,19]\n",
    "classes_31_coe = {index: tmp[index-1] for index in range(1,32)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric code    User's Accuracy      Producer's Accuracy  Class Name                                        \n",
      "1               0.83                 0.85                 Bosque de Coníferas: Oyamel, Ayarín y Cedro       \n",
      "2               0.73                 0.74                 Bosque de Coníferas: de Pino y Táscate            \n",
      "3               0.62                 0.58                 Bosque de Encino y Bosque de Galería              \n",
      "4               0.52                 0.65                 Chaparral                                         \n",
      "5               0.53                 0.81                 Mezquital y Matorral Submontano                   \n",
      "6               0.72                 0.89                 Bosque Mesófilo y Selva Baja Perennifolia         \n",
      "7               0.92                 0.75                 Selva Baja y Mediana Subperennifolia, Bosque de Galería y Palmar Natural\n",
      "8               0.91                 0.83                 Manglar y Petén                                   \n",
      "9               0.89                 0.90                 Selva Mediana y Alta Perennifolia                 \n",
      "10              0.64                 0.68                 Selva Alta Subperennifolia                        \n",
      "11              0.82                 0.76                 Selva Baja Caducifolia Subcaducifolia y Matorral Subtropical\n",
      "12              0.77                 0.91                 Selva Mediana Caducifolia y Subcaducifolia        \n",
      "13              0.76                 0.66                 Mezquital Xerofilo Galeria y Desertico Microfilo  \n",
      "14              0.19                 0.88                 Matorral Crasicaule                               \n",
      "15              0.84                 0.74                 Matorral Espinoso Tamaulipeco                     \n",
      "16              0.36                 0.87                 Matorral Sarco-Crasicaule                         \n",
      "17              0.02                 0.47                 Matorral Sarcocaule                               \n",
      "18              0.67                 0.52                 Matorral Sarco-Crasicaule de Neblina              \n",
      "19              0.97                 1.00                 Matorral Rosetofilo Costero                       \n",
      "20              0.58                 0.92                 Matorral Desertico Rosetofilo                     \n",
      "21              0.40                 0.57                 Popal                                             \n",
      "22              0.55                 0.78                 Tular                                             \n",
      "23              0.41                 0.86                 Vegetacion de Dunas Costeras                      \n",
      "24              0.89                 0.56                 Vegetacion de Desiertos Arenosos                  \n",
      "25              0.62                 0.83                 Vegetacion Halofila Hidrofila                     \n",
      "26              0.85                 0.78                 Vegetacion Halofila Xerofila y Gipsofila          \n",
      "27              0.64                 0.55                 Pastizales                                        \n",
      "28              0.66                 0.73                 Tierras Agricolas                                 \n",
      "29              0.64                 0.33                 Urbano y Construido                               \n",
      "30              0.66                 0.95                 Suelo Desnudo                                     \n",
      "31              0.75                 0.34                 Agua                                              \n",
      "-----\n",
      "Overall Accuracy: 0.69\n",
      "\n",
      "-----\n",
      "Confusion matrix\n",
      "-----\n",
      "      | 1       2       3       4       5       6       7       8       9       10      11      12      13      14      15      16      17      18      19      20      21      22      23      24      25      26      27      28      29      30      31     \n",
      "      | ------- ------- ------- ------- ------- ------- ------- ------- ------- ------- ------- ------- ------- ------- ------- ------- ------- ------- ------- ------- ------- ------- ------- ------- ------- ------- ------- ------- ------- ------- -------\n",
      "1     | 895.00  162.00  0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   \n",
      "2     | 176.00  53270.00 12264.00 275.00  1985.00 1993.00 0.00    0.00    8.00    0.00    557.00  19.00   0.00    918.00  0.00    0.00    0.00    0.00    0.00    0.00    0.00    1.00    0.00    46.00   1.00    0.00    0.00    93.00   0.00    0.00    0.00   \n",
      "3     | 0.00    16169.00 46898.00 713.00  2467.00 135.00  0.00    0.00    0.00    0.00    6808.00 94.00   3.00    5380.00 0.00    0.00    0.00    477.00  0.00    22.00   0.00    37.00   0.00    332.00  10.00   0.00    0.00    666.00  0.00    0.00    0.00   \n",
      "4     | 0.00    307.00  685.00  6209.00 383.00  0.00    0.00    0.00    0.00    0.00    43.00   0.00    41.00   227.00  0.00    0.00    0.00    60.00   0.00    3.00    251.00  100.00  1.00    17.00   31.00   0.00    411.00  742.00  0.00    0.00    0.00   \n",
      "5     | 0.00    96.00   674.00  324.00  12333.00 70.00   0.00    0.00    22.00   0.00    208.00  16.00   6.00    86.00   0.00    7.00    0.00    60.00   4.00    821.00  9.00    49.00   0.00    130.00  28.00   0.00    0.00    252.00  0.00    2.00    0.00   \n",
      "6     | 8.00    258.00  7.00    0.00    9.00    7452.00 0.00    0.00    624.00  0.00    1.00    2.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   \n",
      "7     | 0.00    0.00    0.00    0.00    35.00   0.00    15823.00 604.00  787.00  202.00  1.00    3313.00 0.00    0.00    0.00    0.00    0.00    126.00  0.00    1.00    0.00    1.00    0.00    1.00    0.00    0.00    0.00    0.00    34.00   118.00  0.00   \n",
      "8     | 0.00    0.00    0.00    0.00    0.00    0.00    62.00   7575.00 0.00    0.00    0.00    1.00    0.00    0.00    0.00    36.00   0.00    0.00    215.00  0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    3.00    1222.00 0.00   \n",
      "9     | 0.00    3.00    0.00    0.00    105.00  725.00  377.00  2.00    12971.00 4.00    0.00    71.00   0.00    0.00    0.00    0.00    0.00    85.00   0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    6.00    0.00    0.00   \n",
      "10    | 0.00    0.00    0.00    0.00    0.00    0.00    117.00  0.00    58.00   374.00  0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   \n",
      "11    | 0.00    371.00  7246.00 1105.00 1899.00 0.00    0.00    5.00    0.00    0.00    57705.00 1538.00 1.00    2297.00 0.00    18.00   0.00    110.00  11.00   294.00  14.00   2310.00 0.00    623.00  2.00    0.00    0.00    57.00   0.00    34.00   6.00   \n",
      "12    | 0.00    14.00   30.00   0.00    119.00  4.00    880.00  14.00   184.00  0.00    465.00  17114.00 0.00    0.00    0.00    0.00    0.00    20.00   0.00    0.00    0.00    0.00    0.00    12.00   0.00    0.00    0.00    0.00    0.00    7.00    0.00   \n",
      "13    | 0.00    0.00    127.00  386.00  11.00   0.00    0.00    0.00    0.00    0.00    38.00   0.00    65694.00 1477.00 1038.00 438.00  1823.00 5123.00 0.00    2421.00 3262.00 3646.00 394.00  1709.00 1511.00 21.00   13.00   10087.00 0.00    0.00    0.00   \n",
      "14    | 0.00    35.00   175.00  57.00   4.00    0.00    0.00    0.00    0.00    0.00    34.00   0.00    29.00   6559.00 0.00    0.00    0.00    315.00  0.00    0.00    0.00    2.00    0.00    68.00   2.00    0.00    0.00    194.00  0.00    0.00    0.00   \n",
      "15    | 0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    291.00  0.00    5511.00 206.00  1244.00 0.00    0.00    0.00    21.00   0.00    0.00    0.00    7.00    205.00  0.00    0.00    0.00    0.00    1.00   \n",
      "16    | 0.00    0.00    0.00    0.00    0.00    0.00    0.00    1.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    1845.00 40.00   2.00    29.00   0.00    2.00    0.00    4.00    7.00    24.00   97.00   0.00    0.00    0.00    58.00   1.00   \n",
      "17    | 0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    27.00   0.00    4.00    2.00    90.00   0.00    0.00    2.00    3.00    2.00    1.00    0.00    3.00    19.00   14.00   26.00   0.00    0.00    0.00   \n",
      "18    | 0.00    82.00   3320.00 397.00  158.00  0.00    0.00    0.00    0.00    0.00    315.00  0.00    8853.00 9434.00 0.00    12.00   20.00   36328.00 0.00    686.00  37.00   78.00   30.00   4754.00 833.00  2.00    2.00    4864.00 0.00    0.00    2.00   \n",
      "19    | 0.00    0.00    0.00    0.00    0.00    0.00    0.00    24.00   0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    14134.00 0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    18.00   0.00   \n",
      "20    | 0.00    0.00    0.00    0.00    805.00  0.00    0.00    0.00    0.00    0.00    12.00   0.00    162.00  0.00    0.00    42.00   0.00    117.00  0.00    16777.00 20.00   119.00  0.00    99.00   64.00   0.00    0.00    71.00   0.00    1.00    0.00   \n",
      "21    | 0.00    0.00    6.00    81.00   5.00    0.00    0.00    0.00    0.00    0.00    5.00    0.00    209.00  0.00    2.00    87.00   90.00   1.00    0.00    14.00   6721.00 3711.00 407.00  2.00    61.00   0.00    198.00  102.00  0.00    0.00    1.00   \n",
      "22    | 0.00    0.00    37.00   27.00   11.00   0.00    0.00    0.00    0.00    0.00    123.00  0.00    430.00  0.00    0.00    34.00   105.00  8.00    3.00    43.00   3074.00 17273.00 684.00  25.00   81.00   3.00    63.00   13.00   0.00    0.00    1.00   \n",
      "23    | 0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    2.00    0.00    0.00    50.00   23.00   0.00    0.00    0.00    123.00  102.00  1977.00 2.00    3.00    2.00    0.00    0.00    0.00    0.00    3.00   \n",
      "24    | 0.00    2154.00 4286.00 945.00  2768.00 0.00    0.00    4.00    0.00    0.00    3700.00 16.00   3924.00 7454.00 0.00    1657.00 36.00   9840.00 41.00   6752.00 538.00  3085.00 1266.00 74447.00 8256.00 1.00    36.00   1347.00 13.00   262.00  13.00  \n",
      "25    | 0.00    1.00    13.00   58.00   78.00   0.00    0.00    0.00    0.00    0.00    3.00    0.00    579.00  57.00   0.00    344.00  118.00  137.00  0.00    278.00  156.00  407.00  47.00   824.00  18918.00 8.00    0.00    744.00  0.00    0.00    1.00   \n",
      "26    | 0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    18.00   0.00    28.00   267.00  95.00   1.00    191.00  0.00    15.00   2.00    4.00    0.00    74.00   2542.00 0.00    0.00    0.00    0.00    16.00  \n",
      "27    | 0.00    0.00    0.00    235.00  0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    1.00    79.00   0.00    0.00    0.00    809.00  13.00   5.00    0.00    0.00    0.00    1368.00 0.00    0.00    0.00    0.00   \n",
      "28    | 0.00    39.00   205.00  1084.00 231.00  0.00    0.00    0.00    0.00    0.00    11.00   0.00    5827.00 1351.00 0.00    2.00    2.00    1644.00 0.00    737.00  1626.00 403.00  0.00    117.00  504.00  0.00    46.00   38054.00 0.00    0.00    0.00   \n",
      "29    | 0.00    0.00    0.00    0.00    0.00    0.00    0.00    5.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    1.00    0.00    35.00   0.00    0.00    0.00    0.00    0.00    2.00    0.00    0.00    0.00    0.00    123.00  202.00  0.00   \n",
      "30    | 0.00    0.00    0.00    0.00    2.00    0.00    0.00    127.00  0.00    0.00    0.00    0.00    0.00    0.00    0.00    32.00   0.00    0.00    14.00   2.00    0.00    0.00    0.00    2.00    0.00    0.00    0.00    0.00    14.00   3806.00 1.00   \n",
      "31    | 0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    76.00   73.00   0.00    1.00    0.00    0.00    5.00    8.00    0.00    9.00    92.00   1.00    0.00    0.00    0.00    138.00 \n"
     ]
    }
   ],
   "source": [
    "# confusion matrix and producer and user accuracies\n",
    "scheme = 'madmex_31'\n",
    "\n",
    "acc_dict = validate(y_true=[classes_31_coe[x] for x in coe_y], y_pred=[classes_31_coe[x] for x in y_pred_coe_xgb],\n",
    "#acc_dict = validate(y_true=coe_y, y_pred=y_pred_coe_xgb,\n",
    "                            scheme=scheme)\n",
    "pprint_val_dict(acc_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
