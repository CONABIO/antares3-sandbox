{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from madmex.util import parser_extra_args, join_dicts\n",
    "from madmex.models import ChangeInformation\n",
    "from madmex.wrappers import gwf_query\n",
    "from importlib import import_module\n",
    "from datacube.api import GridWorkflow\n",
    "import numpy\n",
    "#from madmex.lcc.transform.mad import Transform as MAD\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_mad(X, Y, lmbda=0.0, weights=None, bands=1, rows=5002, cols=5002):\n",
    "        #weights = weights\n",
    "        if weights is None:\n",
    "            weights = numpy.ones((rows, cols))\n",
    "        W = weights * numpy.ones(X.shape)\n",
    "        X_mean = numpy.average(X, weights=W, axis=(1,2))\n",
    "        Y_mean = numpy.average(Y, weights=W, axis=(1,2))\n",
    "        X_centered = (X - X_mean[:,numpy.newaxis,numpy.newaxis])\n",
    "        Y_centered = (Y - Y_mean[:,numpy.newaxis,numpy.newaxis])\n",
    "\n",
    "        X_weigthed = X_centered * weights\n",
    "        Y_weigthed = Y_centered * weights\n",
    "        X_pixel_band = X_centered.reshape(bands, rows * cols)\n",
    "        Y_pixel_band = Y_centered.reshape(bands, rows * cols)\n",
    "\n",
    "        X_pixel_band_weigthed = X_weigthed.reshape(bands, rows * cols)\n",
    "        Y_pixel_band_weigthed = Y_weigthed.reshape(bands, rows * cols)\n",
    "\n",
    "        sigma_11 = numpy.matmul(X_pixel_band_weigthed, X_pixel_band.T) / (numpy.sum(weights) - 1)\n",
    "        sigma_11 = (1-lmbda) * sigma_11 + lmbda * numpy.eye(bands)\n",
    "        sigma_22 = numpy.matmul(Y_pixel_band_weigthed, Y_pixel_band.T) / (numpy.sum(weights) - 1)\n",
    "        sigma_22 = (1-lmbda) * sigma_22 + lmbda * numpy.eye(bands)\n",
    "        sigma_12 = numpy.matmul(X_pixel_band_weigthed, Y_pixel_band.T) / (numpy.sum(weights) - 1)\n",
    "        lower_11 = numpy.linalg.cholesky(sigma_11)\n",
    "        lower_22 = numpy.linalg.cholesky(sigma_22)\n",
    "        lower_11_inverse = numpy.round(numpy.linalg.inv(lower_11), decimals=10)\n",
    "        lower_22_inverse = numpy.round(numpy.linalg.inv(lower_22), decimals=10)\n",
    "        sigma_11_inverse = numpy.linalg.inv(sigma_11)\n",
    "        sigma_22_inverse = numpy.linalg.inv(sigma_22)\n",
    "\n",
    "        eig_problem_1 = numpy.matmul(lower_11_inverse,\n",
    "                                     numpy.matmul(sigma_12,\n",
    "                                                  numpy.matmul(sigma_22_inverse,\n",
    "                                                               numpy.matmul(sigma_12.T, lower_11_inverse.T))))\n",
    "        eig_problem_1 = (eig_problem_1 + eig_problem_1.T) * 0.5\n",
    "        eig_problem_2 = numpy.matmul(lower_22_inverse,\n",
    "                                     numpy.matmul(sigma_12.T,\n",
    "                                                  numpy.matmul(sigma_11_inverse,\n",
    "                                                               numpy.matmul(sigma_12, lower_22_inverse.T))))\n",
    "        eig_problem_2 = (eig_problem_2 + eig_problem_2.T) * 0.5\n",
    "        eig_values_1, eig_vectors_1 = numpy.linalg.eig(eig_problem_1)\n",
    "        eig_values_2, eig_vectors_2 = numpy.linalg.eig(eig_problem_2)\n",
    "\n",
    "        eig_vectors_transformed_1 = numpy.matmul(lower_11_inverse.T, eig_vectors_1)\n",
    "        eig_vectors_transformed_2 = numpy.matmul(lower_22_inverse.T, eig_vectors_2)\n",
    "\n",
    "        sort_index_1 = numpy.flip(eig_values_1.argsort(), 0)\n",
    "        sort_index_2 = numpy.flip(eig_values_2.argsort(), 0)\n",
    "\n",
    "        vector_u = eig_vectors_transformed_1[:, sort_index_1]\n",
    "        vector_v = eig_vectors_transformed_2[:, sort_index_2]\n",
    "\n",
    "        mu = numpy.sqrt(eig_values_2[sort_index_2])\n",
    "        norm_a_squared = numpy.diag(numpy.matmul(vector_u.T, vector_u))\n",
    "        norm_b_squared = numpy.diag(numpy.matmul(vector_v.T, vector_v))\n",
    "\n",
    "        variance_u = numpy.diag(1/numpy.sqrt(numpy.diag(sigma_11)))\n",
    "        s = numpy.sum(numpy.matmul(variance_u, numpy.matmul(sigma_11, vector_u)),axis=0)\n",
    "        vector_u = numpy.matmul(vector_u, numpy.diag(s / numpy.abs(s)))\n",
    "\n",
    "        signs_vector = numpy.diag(numpy.dot(numpy.dot(vector_u.T, sigma_12), vector_v))\n",
    "        signs = numpy.diag(signs_vector / numpy.abs(signs_vector))\n",
    "        vector_v = numpy.matmul(vector_v, signs)\n",
    "\n",
    "        U = numpy.matmul(vector_u.T, X_pixel_band)\n",
    "        V = numpy.matmul(vector_v.T, Y_pixel_band)\n",
    "        M = U - V\n",
    "        sigma_squared = (2 - lmbda * (norm_a_squared + norm_b_squared)) / (1 - lmbda) - 2 * mu\n",
    "        rho = mu * (1 - lmbda) / numpy.sqrt((1 - lmbda * norm_a_squared) * (1 - lmbda * norm_b_squared))\n",
    "        return M.reshape(bands, rows, cols), sigma_squared, rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = 'imadmaf'\n",
    "band_list = None\n",
    "name = 'test4_JAL_2017_2018'\n",
    "product_pre = 's1_2_20mres10m_JAL_recipe2017'\n",
    "product_post = 's1_2_20m_resampled_10m_001_Jalisco_from_s3_to_s3_recipe_2018'\n",
    "lc_pre = 'land_cover_rf_s1_2_20mres10m_JAL_recipe2017'\n",
    "lc_post = 'land_cover_rf_s1_2_20m_resampled_10m_001_jalisco_2018_mxnb_31_02'\n",
    "year_pre = 2017\n",
    "year_post = 2018\n",
    "filter_labels = True\n",
    "mmu = 5000.0\n",
    "extra_args = parser_extra_args('')\n",
    "scheduler_file = None\n",
    "#options = {'lat': [20.833, 21.125], 'long': [-103.1395, -102.796], 'region': None}\n",
    "options = {'lat': [20.04, 20.401], 'long': [-103.1395, -102.796], 'region': None}\n",
    "#options = {'lat': [20.04, 20.401], 'long': [-103.48275, -103.1395, 'region': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_meta, _ = ChangeInformation.objects.get_or_create(year_pre=year_pre,\n",
    "                                                          year_post=year_post,\n",
    "                                                          algorithm=algorithm,\n",
    "                                                          name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build gwf_kwargs, send a query for both products, combine the dict and generate iterable\n",
    "gwf_kwargs = { k: options[k] for k in ['lat', 'long', 'region']}\n",
    "pre_dict = gwf_query(product_pre, view=False, **gwf_kwargs)\n",
    "post_dict = gwf_query(product_post, view=False, **gwf_kwargs)\n",
    "iterable = join_dicts(pre_dict, post_dict, join='inner').items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect and classify starts\n",
    "#module = import_module('madmex.lcc.bitemporal.%s' % algorithm)\n",
    "#BiChange = module.BiChange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load geoarrays\n",
    "geoarray_pre = GridWorkflow.load(list(iterable)[0][1][0], measurements=band_list)\n",
    "#BiChange_pre = BiChange.from_geoarray(geoarray_pre, **extra_args)\n",
    "geoarray_post = GridWorkflow.load(list(iterable)[0][1][1], measurements=band_list)\n",
    "#BiChange_post = BiChange.from_geoarray(geoarray_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run change detection\n",
    "#BiChange_pre.run(BiChange_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr0 = geoarray_pre.squeeze().to_array().values\n",
    "arr1 = geoarray_post.squeeze().to_array().values\n",
    "#affine = Affine(*list(geoarray_pre.affine)[0:6])\n",
    "#crs = geoarray_pre.crs._crs.ExportToProj4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if arr0.ndim == 2:\n",
    "    arr0 = arr0[numpy.newaxis,:]\n",
    "bands, rows, cols = arr0.shape\n",
    "arr0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iterations=25\n",
    "min_delta=0.01\n",
    "lmbda=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IRMAD\n",
    "i = 0\n",
    "delta = 1.0\n",
    "old_rho = numpy.ones((arr0.shape[0]))\n",
    "weights = numpy.ones((arr0.shape[1],arr0.shape[2]))\n",
    "while i < max_iterations and delta > min_delta:\n",
    "    print('Iteration #%s' % i)\n",
    "    print('delta: %s' % delta)\n",
    "    M, sigma_squared, rho = transform_mad(arr0, arr1, lmbda=lmbda, weights=weights, bands=bands, rows=rows, cols=cols)\n",
    "    chi_square = numpy.tensordot(1 / sigma_squared, numpy.multiply(M, M), axes=1)\n",
    "    weights = 1 - stats.chi2.cdf(chi_square, bands)\n",
    "    delta = max(abs(rho - old_rho))\n",
    "    old_rho = rho\n",
    "    i = i + 1\n",
    "M"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
