{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizar histogram matching de acuerdo a:\n",
    "\n",
    "https://github.com/CONABIO/antares3/blob/training-data-model-fit/madmex/lcc/bitemporal/distance.py#L5\n",
    "\n",
    "# 1\n",
    "\n",
    "Registrar productos de surfaces reflectances del año 95-96 (algunas escenas) disponibles en s3.\n",
    "\n",
    "Se eligió el dc tile: (21,-19) definido de acuerdo al tiling en los archivos de configuración del satélite landsat de antares3.\n",
    "\n",
    "Este dc tile corresponde al path/row: 032 042 (Durango) y de las escenas que están disponibles en s3 para el año 95-96 están:\n",
    "\n",
    "LT050320421995020601T1-SC20180529121712/\n",
    "LT050320421995031001T1-SC20180529121554/\n",
    "LT050320421995041101T1-SC20180529121727/\n",
    "LT050320421995051301T1-SC20180529121345/\n",
    "LT050320421995100401T1-SC20180529121414/\n",
    "LT050320421995102001T1-SC20180529120628/\n",
    "LT050320421995112101T1-SC20180529121834/\n",
    "LT050320421996010801T2-SC20180529123117/\n",
    "LT050320421996012401T2-SC20180529122022/\n",
    "LT050320421996031201T1-SC20180529122036/\n",
    "LT050320421996041301T1-SC20180529121850/\n",
    "LT050320421996042901T1-SC20180529121810/\n",
    "LT050320421996051501T1-SC20180529122435/\n",
    "LT050320421996102201T1-SC20180529123018/\n",
    "LT050320421996110701T1-SC20180529122414/\n",
    "LT050320421996112301T1-SC20180529121903/\n",
    "\n",
    "Se eligen registrar:\n",
    "\n",
    "LT050320421995020601T1-SC20180529121712/\n",
    "LT050320421995031001T1-SC20180529121554/\n",
    "LT050320421995112101T1-SC20180529121834/\n",
    "LT050320421996012401T2-SC20180529122022/\n",
    "LT050320421996031201T1-SC20180529122036/\n",
    "LT050320421996110701T1-SC20180529122414/\n",
    "LT050320421996112301T1-SC20180529121903/\n",
    "\n",
    "y se copian a :\n",
    "\n",
    "```\n",
    "/LUSTRE/MADMEX/tasks/2019_tasks/histogram_matching/scenes_95_96/\n",
    "\n",
    "/shared_volume/tasks/2019_tasks/histogram_matching/scenes_95_96/\n",
    "```\n",
    "\n",
    "Pasos de prepare, product add, dataset add e ingest:\n",
    "\n",
    "\n",
    "```\n",
    "antares prepare_metadata --path /shared_volume/tasks/2019_tasks/histogram_matching/scenes_95_96/ --dataset_name landsat_espa --outfile metadata_mex_l5.yaml -sc /shared_volume/scheduler.json\n",
    "\n",
    "datacube -v product add ~/.config/madmex/indexing/ls5_espa_scenes.yaml\n",
    "\n",
    "datacube -v dataset add metadata_mex_l5.yaml\n",
    "\n",
    "datacube -v ingest -c ~/.config/madmex/ingestion/ls5_espa_mexico.yaml --executor distributed 172.17.0.2:8786\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check via cmd line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "datacube product list\n",
    "\n",
    "```\n",
    "ls5_espa_mexico Landsat 5 Collection 1 processed to surface reflectance by espa. Resampled to 30m Mexico INEGI Lambert Conformal Conic projection with a 50 km tile size.\n",
    "ls5_espa_scene  Landsat 5 Collection 1 Higher Level SR scene processed by ESPA. 30m UTM based projection.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2\n",
    "\n",
    "Registrar los productos de las recetas (dc tile: (21,-19) para años 2014-2015) de acuerdo al notebook:\n",
    "\n",
    "https://github.com/CONABIO/antares3-sandbox/blob/master/notebooks/ingest_recipe_products/ingest_recipe_products.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 histogram matching\n",
    "\n",
    "Uso de: https://github.com/CONABIO/antares3/blob/training-data-model-fit/madmex/lcc/bitemporal/distance.py#L5\n",
    "\n",
    "Referencias:\n",
    "\n",
    "https://github.com/mapbox/rio-hist\n",
    "\n",
    "https://blog.mapbox.com/color-balancing-imagery-with-histogram-matching-be1b38c28509\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A) Cargar producto de años `source` (1995-1996)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "from datacube.api import GridWorkflow\n",
    "\n",
    "from madmex.wrappers import gwf_query\n",
    "from madmex.util import join_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "product = ['ls5_espa_mexico']\n",
    "begin = '1995-01-01'\n",
    "end = '1996-12-31'\n",
    "region = 'Durango'\n",
    "gwf_kwargs = {'region': region, 'begin': begin, 'end': end}\n",
    "dc_tile=(21,-19)\n",
    "dict_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prod in product:\n",
    "    gwf_kwargs.update(product = prod)\n",
    "    try:\n",
    "        dict_list.append(gwf_query(**gwf_kwargs, view=False))\n",
    "    # Exception is in case one of the product hasn't been registered in the datacube\n",
    "    except Exception as e:\n",
    "        pass\n",
    "iterable = join_dicts(*dict_list, join='full').items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_iter = list(iterable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = [x for x in range(0,len(lista_iter)) if lista_iter[x][0] == dc_tile]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_source = lista_iter[index[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21, -19), [Tile<sources=<xarray.DataArray (time: 7)>\n",
       "  array([(Dataset <id=979bee9a-40f0-4e12-bd21-86d0d2db3087 type=ls5_espa_mexico location=file:///shared_volume/datacube/datacube_ingest/LS5_espa/mexico/LS5_espa_21_-19_19950206164648000000.nc>,),\n",
       "         (Dataset <id=4c9a2386-597c-405c-bbd9-f076e077ff71 type=ls5_espa_mexico location=file:///shared_volume/datacube/datacube_ingest/LS5_espa/mexico/LS5_espa_21_-19_19950310164531000000.nc>,),\n",
       "         (Dataset <id=b817293f-7dda-48a8-a7d6-1a95dee6ab6d type=ls5_espa_mexico location=file:///shared_volume/datacube/datacube_ingest/LS5_espa/mexico/LS5_espa_21_-19_19951121163445000000.nc>,),\n",
       "         (Dataset <id=37a54d8c-88e4-4883-8e41-d02830400be5 type=ls5_espa_mexico location=file:///shared_volume/datacube/datacube_ingest/LS5_espa/mexico/LS5_espa_21_-19_19960124163902000000.nc>,),\n",
       "         (Dataset <id=98f4c96b-fbd2-4441-8195-6529852872df type=ls5_espa_mexico location=file:///shared_volume/datacube/datacube_ingest/LS5_espa/mexico/LS5_espa_21_-19_19960312164217000000.nc>,),\n",
       "         (Dataset <id=87c341cc-0797-43d5-bad4-4577d05f6ef8 type=ls5_espa_mexico location=file:///shared_volume/datacube/datacube_ingest/LS5_espa/mexico/LS5_espa_21_-19_19961107165532000000.nc>,),\n",
       "         (Dataset <id=f076f63b-5ad1-4393-954e-5b11166a8a35 type=ls5_espa_mexico location=file:///shared_volume/datacube/datacube_ingest/LS5_espa/mexico/LS5_espa_21_-19_19961123165617000000.nc>,)],\n",
       "        dtype=object)\n",
       "  Coordinates:\n",
       "    * time     (time) datetime64[ns] 1995-02-06T16:46:48 ... 1996-11-23T16:56:17,\n",
       "  \tgeobox=GeoBox(1667, 1667, Affine(30.0, 0.0, 2027370.0,\n",
       "         0.0, -30.0, 1526540.0), PROJCS[\"unnamed\",GEOGCS[\"WGS 84\",DATUM[\"unknown\",SPHEROID[\"WGS84\",6378137,6556752.3141]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433]],PROJECTION[\"Lambert_Conformal_Conic_2SP\"],PARAMETER[\"standard_parallel_1\",17.5],PARAMETER[\"standard_parallel_2\",29.5],PARAMETER[\"latitude_of_origin\",12],PARAMETER[\"central_meridian\",-102],PARAMETER[\"false_easting\",2500000],PARAMETER[\"false_northing\",0]])>])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B) Cargar producto de años `template` (2014-2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "product = ['recipe_mex_L7L8_1415']\n",
    "begin = '2014-01-01'\n",
    "end = '2015-12-31'\n",
    "region = 'Durango'\n",
    "gwf_kwargs = {'region': region,  'begin': begin, 'end': end}\n",
    "dc_tile=(21,-19)\n",
    "dict_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prod in product:\n",
    "    gwf_kwargs.update(product = prod)\n",
    "    try:\n",
    "        dict_list.append(gwf_query(**gwf_kwargs, view=False))\n",
    "    # Exception is in case one of the product hasn't been registered in the datacube\n",
    "    except Exception as e:\n",
    "        pass\n",
    "iterable = join_dicts(*dict_list, join='full').items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_iter_template = list(iterable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_template = [x for x in range(0,len(lista_iter_template)) if lista_iter_template[x][0] == dc_tile]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_template = lista_iter_template[index_template[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21, -19), [Tile<sources=<xarray.DataArray (time: 1)>\n",
       "  array([(Dataset <id=68d0425b-0a05-5455-a0f4-2bb2029abb86 type=recipe_mex_L7L8_1415 location=file://shared_volume/datacube/datacube_ingest/recipes/recipe_mex_L7L8_1415/madmex_003_21_-19_2014-12-31.nc>,)],\n",
       "        dtype=object)\n",
       "  Coordinates:\n",
       "    * time     (time) datetime64[ns] 2014-12-31T12:00:00,\n",
       "  \tgeobox=GeoBox(1667, 1667, Affine(30.0, 0.0, 2027370.0,\n",
       "         0.0, -30.0, 1526540.0), PROJCS[\"unnamed\",GEOGCS[\"WGS 84\",DATUM[\"unknown\",SPHEROID[\"WGS84\",6378137,6556752.3141]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433]],PROJECTION[\"Lambert_Conformal_Conic_2SP\"],PARAMETER[\"standard_parallel_1\",17.5],PARAMETER[\"standard_parallel_2\",29.5],PARAMETER[\"latitude_of_origin\",12],PARAMETER[\"central_meridian\",-102],PARAMETER[\"false_easting\",2500000],PARAMETER[\"false_northing\",0]])>])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr_template = xr.auto_combine([GridWorkflow.load(x, dask_chunks={'x': 600, 'y': 600}) for x in var_template[1]], concat_dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr_template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C) Masking de `source` (antes de cálculo de métricas en recetas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "from datacube.storage import masking\n",
    "\n",
    "from madmex.util.xarray import to_float, to_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "crs = var_source[1][0].geobox.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr_source = xr.auto_combine([GridWorkflow.load(x, dask_chunks={'x': 600, 'y': 600}) for x in var_source[1]], concat_dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr_source.attrs['geobox'] = var_source[1][0].geobox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear = masking.make_mask(sr_source.pixel_qa, cloud=False, cloud_shadow=False,\n",
    "                          snow=False)\n",
    "sr_source_1 = sr_source.where(clear)\n",
    "sr_source_1 = sr_source_1.drop('pixel_qa')\n",
    "sr_source_1 = sr_source_1.apply(func=to_float, keep_attrs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (time: 7, x: 1667, y: 1667)\n",
       "Coordinates:\n",
       "  * y        (y) float64 1.527e+06 1.526e+06 1.526e+06 ... 1.477e+06 1.477e+06\n",
       "  * x        (x) float64 2.027e+06 2.027e+06 2.027e+06 ... 2.077e+06 2.077e+06\n",
       "  * time     (time) datetime64[ns] 1995-02-06T16:46:48 ... 1996-11-23T16:56:17\n",
       "Data variables:\n",
       "    blue     (time, y, x) float64 dask.array<shape=(7, 1667, 1667), chunksize=(7, 600, 600)>\n",
       "    green    (time, y, x) float64 dask.array<shape=(7, 1667, 1667), chunksize=(7, 600, 600)>\n",
       "    red      (time, y, x) float64 dask.array<shape=(7, 1667, 1667), chunksize=(7, 600, 600)>\n",
       "    nir      (time, y, x) float64 dask.array<shape=(7, 1667, 1667), chunksize=(7, 600, 600)>\n",
       "    swir1    (time, y, x) float64 dask.array<shape=(7, 1667, 1667), chunksize=(7, 600, 600)>\n",
       "    swir2    (time, y, x) float64 dask.array<shape=(7, 1667, 1667), chunksize=(7, 600, 600)>\n",
       "Attributes:\n",
       "    geobox:   GeoBox(Geometry({'type': 'Polygon', 'coordinates': [[(-106.7330..."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr_source_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D) Histogram matching para cada banda de source tomando referencia bandas de template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
