{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fiona\n",
    "import hashlib\n",
    "import boto3\n",
    "import json\n",
    "import numpy as np\n",
    "import datacube\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "from datacube.api import GridWorkflow\n",
    "from madmex.wrappers import gwf_query\n",
    "from madmex.models import SegmentationInformation\n",
    "from madmex.util import parser_extra_args\n",
    "from madmex.settings import TEMP_DIR\n",
    "from importlib import import_module\n",
    "import gc\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_of_product = 's2_10m_scl_Jalisco_some_scenes_recipe_2018'\n",
    "gwf_kwargs = {'region': 'Jalisco', 'begin': '2018-01-01', 'end':'2018-12-31'}\n",
    "gwf_kwargs.update(product=name_of_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterable = gwf_query(**gwf_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_iter = list(iterable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = lista_iter[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = 'bis'\n",
    "datasource = 'sentinel2'\n",
    "name = 's2_10m_some_scenes_fiona_test'\n",
    "year = '2018'\n",
    "extra_args = parser_extra_args(['t=30','s=0.5','c=0.7'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta, _ = SegmentationInformation.objects.get_or_create(\n",
    "    algorithm=algorithm, datasource=datasource,\n",
    "    parameters=json.dumps(extra_args),\n",
    "    datasource_year=year,\n",
    "    name=name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = datasource + '_%d_%d_' % (var[0][0], var[0][1]) + year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sentinel2_28_-28_2018'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(TEMP_DIR, 'segmentation_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "band_list = ['ndvi_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    module = import_module('madmex.segmentation.%s' % algorithm)\n",
    "    Segmentation = module.Segmentation\n",
    "except ImportError as e:\n",
    "    raise ValueError('Invalid model argument')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Anticipated allocation: 879609KB\n",
      "    ...allocated\n",
      "  thresh 1\n",
      "  thresh 2\n",
      "  thresh 3\n",
      "  thresh 4\n",
      "  thresh 5\n",
      "  thresh 6\n",
      "  thresh 7\n",
      "  thresh 8\n",
      "  thresh 9\n",
      "  thresh 10\n",
      "  thresh 11\n",
      "  thresh 12\n",
      "  thresh 13\n",
      "  thresh 14\n",
      "  thresh 15\n",
      "  thresh 16\n",
      "  thresh 17\n",
      "  thresh 18\n",
      "  thresh 19\n",
      "  thresh 20\n",
      "  thresh 21\n",
      "  thresh 22\n",
      "  thresh 23\n",
      "  thresh 24\n",
      "  thresh 25\n",
      "  thresh 26\n",
      "  thresh 27\n",
      "  thresh 28\n",
      "  thresh 29\n",
      "  thresh 30\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Load tile\n",
    "    geoarray = GridWorkflow.load(var[1], measurements=band_list)\n",
    "    seg = Segmentation.from_geoarray(geoarray, **extra_args)\n",
    "    seg.segment()\n",
    "    # Try deallocating input array\n",
    "    seg.array = None\n",
    "    geoarray = None\n",
    "    seg.polygonize()\n",
    "    # Write to shapefile\n",
    "    hash = hashlib.md5(dataset_name.encode('utf-8')).hexdigest()[0:6]\n",
    "    name_file = hash + '_' + dataset_name\n",
    "    out_file = path + '/' + name_file\n",
    "    schema = {'geometry': 'Polygon',\n",
    "          'properties': [('id', 'int')]}\n",
    "    with fiona.open(path, 'w', layer = name_file,\n",
    "                    schema=schema,\n",
    "                    driver='ESRI Shapefile',\n",
    "                    crs=seg.crs) as dst:\n",
    "        for feature in seg.fc:\n",
    "            dst.write(feature)\n",
    "\n",
    "    #Upload to s3 bucket\n",
    "    s3 = boto3.client('s3')\n",
    "    bucket_name = 'my-segmentation-bucket'\n",
    "    filename = name_file + '.shp'\n",
    "    filepath = path + '/' + filename\n",
    "    s3.upload_file(filepath, bucket_name, filename)\n",
    "    os.remove(filepath)\n",
    "    filename = name_file + '.shx'\n",
    "    filepath = path + '/' + filename\n",
    "    s3.upload_file(filepath, bucket_name, filename)\n",
    "    os.remove(filepath)\n",
    "    filename = name_file + '.cpg'\n",
    "    filepath = path + '/' + filename\n",
    "    s3.upload_file(filepath, bucket_name, filename)\n",
    "    os.remove(filepath)\n",
    "    filename = name_file + '.dbf'\n",
    "    filepath = path + '/' + filename\n",
    "    s3.upload_file(filepath, bucket_name, filename)\n",
    "    os.remove(filepath)\n",
    "    filename = name_file + '.prj'\n",
    "    filepath = path + '/' + filename\n",
    "    s3.upload_file(filepath, bucket_name, filename)\n",
    "    os.remove(filepath)\n",
    "    gc.collect()\n",
    "except Exception as e:\n",
    "        print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
