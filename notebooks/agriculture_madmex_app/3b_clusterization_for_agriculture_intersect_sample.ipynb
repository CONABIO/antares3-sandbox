{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import json\n",
    "from django.contrib.gis.geos import GEOSGeometry\n",
    "import time \n",
    "import shutil \n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "from shapely.geometry import mapping\n",
    "import pandas as pd\n",
    "import fiona\n",
    "import geopandas as gpd\n",
    "from fiona.crs import to_string\n",
    "from fiona.crs import from_epsg\n",
    "from shapely.geometry import shape, Point, Polygon\n",
    "from fiona.crs import to_string\n",
    "\n",
    "from madmex.overlay.conversions import train_object_to_feature\n",
    "from madmex.util.spatial import geometry_transform\n",
    "from madmex.models import TrainClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7) Random sample para cada categoría generada de Kmeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**La muestra debe generarse de modo que incluya los polígonos dados por inecol más otros y que en total sean al menos 1000**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/LUSTRE/MADMEX/tasks/2020/1_clusterization_for_agriculture_labeling/features_computed/all_dc_tilesndvi-gndvi-avi/03-04-2020/'\n",
    "#next line was added because some dc tiles on the first processing pass weren't successful\n",
    "paths = [\n",
    "#'/LUSTRE/MADMEX/tasks/2020/1_clusterization_for_agriculture_labeling/features_computed/all_dc_tilesndvi-gndvi-avi/03-04-2020/46_-35',\n",
    "#'/LUSTRE/MADMEX/tasks/2020/1_clusterization_for_agriculture_labeling/features_computed/all_dc_tilesndvi-gndvi-avi/03-04-2020/45_-35',\n",
    "'/LUSTRE/MADMEX/tasks/2020/1_clusterization_for_agriculture_labeling/features_computed/all_dc_tilesndvi-gndvi-avi/03-04-2020/45_-34',\n",
    "#'/LUSTRE/MADMEX/tasks/2020/1_clusterization_for_agriculture_labeling/features_computed/all_dc_tilesndvi-gndvi-avi/03-04-2020/44_-36',\n",
    "#'/LUSTRE/MADMEX/tasks/2020/1_clusterization_for_agriculture_labeling/features_computed/all_dc_tilesndvi-gndvi-avi/03-04-2020/43_-35',\n",
    "#'/LUSTRE/MADMEX/tasks/2020/1_clusterization_for_agriculture_labeling/features_computed/all_dc_tilesndvi-gndvi-avi/03-04-2020/43_-34',\n",
    "#'/LUSTRE/MADMEX/tasks/2020/1_clusterization_for_agriculture_labeling/features_computed/all_dc_tilesndvi-gndvi-avi/03-04-2020/41_-30',\n",
    "#'/LUSTRE/MADMEX/tasks/2020/1_clusterization_for_agriculture_labeling/features_computed/all_dc_tilesndvi-gndvi-avi/03-04-2020/40_-34',\n",
    "\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for source_path in glob.iglob(os.path.join(paths, '/*.shp')):\n",
    "#    l.append(source_path)\n",
    "#next line was added because some dc tiles on the first processing pass weren't successful\n",
    "\n",
    "for path in paths:\n",
    "    l.append(glob.glob(os.path.join(path, '*.shp'))[0])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_dc_tiles = [elem.split(\"/\")[9] for elem in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['45_-34']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_dc_tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [elem.split(\"/\")[10].replace('aoi2.shp','') for elem in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['03-04-2020_clusters_45_-34_nclusters_4_']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = 'cultivos2019_inecol'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "No geometry data set yet (expected in column 'geometry'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-07a81a80f36e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m                                                \u001b[0mgdf_poi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                                                \u001b[0mop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'intersects'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                                                how='inner')\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mfile_control\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'finished intersection\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mfile_control\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'extract rows to keep\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/geopandas/tools/sjoin.py\u001b[0m in \u001b[0;36msjoin\u001b[0;34m(left_df, right_df, how, op, lsuffix, rsuffix)\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;31m# tree_idx_df == 'left'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         idxmatch = right_df.geometry.apply(lambda x: x.bounds).apply(\n\u001b[0m\u001b[1;32m    119\u001b[0m             \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         )\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5177\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5178\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5179\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/geopandas/geodataframe.py\u001b[0m in \u001b[0;36m_get_geometry\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    101\u001b[0m             raise AttributeError(\n\u001b[1;32m    102\u001b[0m                 \u001b[0;34m\"No geometry data set yet (expected in\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                 \u001b[0;34m\" column '%s'.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_geometry_column_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m             )\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_geometry_column_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: No geometry data set yet (expected in column 'geometry'."
     ]
    }
   ],
   "source": [
    "for k in range(len(l)):\n",
    "    control = 'processing_' + l_dc_tiles[k] + '.txt'\n",
    "    #file_control = open(path+l_dc_tiles[k]+'/'+control,'w+')\n",
    "    #next line was added because some dc tiles on the first processing pass weren't successful\n",
    "    file_control = open(paths[k]+'/'+control,'w+')\n",
    "    file_control.write('intersection with training set already registered in DB with labels\\n')\n",
    "    gdf_df_clusters = gpd.read_file(l[k])\n",
    "    crs = gdf_df_clusters.crs\n",
    "    nclusters=len(gdf_df_clusters['preds'].unique())\n",
    "    bbox = gdf_df_clusters.total_bounds\n",
    "    p1 = Point(bbox[0], bbox[3])\n",
    "    p2 = Point(bbox[2], bbox[3])\n",
    "    p3 = Point(bbox[2], bbox[1])\n",
    "    p4 = Point(bbox[0], bbox[1])\n",
    "    p1 = shape(geometry_transform(mapping(p1),crs_out=\"+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs\",\n",
    "                                  crs_in=crs))\n",
    "    p2 = shape(geometry_transform(mapping(p2),crs_out=\"+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs\",\n",
    "                                  crs_in=crs))\n",
    "    p3 = shape(geometry_transform(mapping(p3),crs_out=\"+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs\",\n",
    "                                  crs_in=crs))\n",
    "    p4 = shape(geometry_transform(mapping(p4),crs_out=\"+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs\",\n",
    "                                  crs_in=crs))\n",
    "    np1 = (p1.coords.xy[0][0], p1.coords.xy[1][0])\n",
    "    np2 = (p2.coords.xy[0][0], p2.coords.xy[1][0])\n",
    "    np3 = (p3.coords.xy[0][0], p3.coords.xy[1][0])\n",
    "    np4 = (p4.coords.xy[0][0], p4.coords.xy[1][0])\n",
    "    bb_polygon = Polygon([np1, np2, np3, np4])\n",
    "    bb_polygon_for_query = GEOSGeometry(json.dumps(mapping(bb_polygon)))\n",
    "    query_set = TrainClassification.objects.filter(train_object__the_geom__intersects=bb_polygon_for_query,\n",
    "                                                   training_set=training_set).prefetch_related('train_object', 'interpret_tag')\n",
    "    fc_cultivos = [train_object_to_feature(x, to_string(crs)) for x in query_set]\n",
    "    gdf_poi = gpd.GeoDataFrame.from_features([feature for feature in fc_cultivos], crs=crs)\n",
    "    gdf_df_clusters_poi_intersects = gpd.sjoin(gdf_df_clusters.reset_index(drop=True),\n",
    "                                               gdf_poi.reset_index(drop=True),\n",
    "                                               op='intersects',\n",
    "                                               how='inner')\n",
    "    file_control.write('finished intersection\\n')\n",
    "    file_control.write('extract rows to keep\\n')\n",
    "    gdf_df_clusters_keep = gpd.GeoDataFrame()\n",
    "    gdf_df_clusters_keep['features_i'] = gdf_df_clusters_poi_intersects['features_i']\n",
    "    gdf_df_clusters_keep['preds'] = gdf_df_clusters_poi_intersects['preds']\n",
    "    gdf_df_clusters_keep['geometry'] = gdf_df_clusters_poi_intersects['geometry']\n",
    "    gdf_df_clusters_keep['class'] = gdf_df_clusters_poi_intersects['class']\n",
    "    gdf_df_clusters_keep.crs = crs\n",
    "    file_control.write('extract sample that are not in the intersection\\n')\n",
    "    t_keep_rows = tuple(gdf_df_clusters_keep['features_i'])\n",
    "    gdf_df_clusters_to_sample = gdf_df_clusters.loc[~gdf_df_clusters['features_i'].isin(t_keep_rows)]\n",
    "    nmultipolygons=len(gdf_df_clusters_to_sample.index)\n",
    "    total_mpolygons = 1000\n",
    "    if total_mpolygons>len(t_keep_rows):\n",
    "        nsample=total_mpolygons-len(t_keep_rows)\n",
    "    else:\n",
    "        nsample=total_mpolygons   \n",
    "    if nmultipolygons>nsample:\n",
    "        nsample_per_cluster=int(nsample/nclusters)+1\n",
    "        nsample=nsample_per_cluster*nclusters\n",
    "    else:\n",
    "        nsample_per_cluster=int(nmultipolygons/nclusters)+1\n",
    "        nsample=nsample_per_cluster*nclusters\n",
    "    gdf_df_clusters_sample=gdf_df_clusters_to_sample.groupby('preds').apply(lambda s: s.sample(min(len(s),\n",
    "                                                                                                    nsample_per_cluster),\n",
    "                                                                                                random_state=1))\n",
    "    gdf_df_clusters_sample.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "    file_control.write('union of sample and keep polygons\\n')\n",
    "    gdf_sampled_keep = pd.concat([gdf_df_clusters_sample,gdf_df_clusters_keep],\n",
    "                                 ignore_index=True,sort=False).pipe(gpd.GeoDataFrame)\n",
    "    if sum(gdf_sampled_keep['class'].isna())>0:\n",
    "        gdf_sampled_keep.loc[gdf_sampled_keep['class'].isna(),'class'] = ''\n",
    "    \n",
    "    file_control.write('write results to shapefile\\n')\n",
    "    total_mpolygons = len(gdf_sampled_keep.index)\n",
    "    #filename_result = path + l_dc_tiles[k] + '/' + filenames[k] + 'sample_%d' % total_mpolygons + '_with_class_aoi.shp'\n",
    "    #next line was added because some dc tiles on the first processing pass weren't successful\n",
    "    filename_result = paths[k] + '/' + filenames[k] + 'sample_%d' % total_mpolygons + '_with_class_aoi.shp'\n",
    "    gdf_sampled_keep.crs = crs\n",
    "    gdf_sampled_keep.to_file(filename_result)\n",
    "    file_control.write('finished processing\\n')\n",
    "    file_control.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
